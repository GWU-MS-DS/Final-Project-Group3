# -*- coding: utf-8 -*-
"""reddit_scraper.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/188oQYpo-bvgh226XicfxNG8pFY7llsm4
"""

pip install praw

pip install tqdm

from praw.models import user
import praw
import pandas as pd
import prawcore.exceptions

from datetime import datetime, timedelta
import praw


reddit = praw.Reddit(
    client_id="nFKOCvQQEIoW2hFeVG6kfA",
    client_secret="5BBB4fr-HMPtO8f4jZhle74-fYcDkQ",
    user_agent="Icy_Process3191",
)

sub_name = 'pharmacy'

subreddit = reddit.subreddit(sub_name)


posts = subreddit.top(limit=None)


posts_list = list(posts)
posts_list.sort(key=lambda post: post.created_utc, reverse=True)


interval = 'weekly'
top_comments_count = 3

intervals = {
    'daily': timedelta(days=1),
    'weekly': timedelta(weeks=1),
    'monthly': timedelta(weeks=4)
}


end_time = datetime.utcfromtimestamp(posts_list[0].created_utc)


nested_posts = []
current_interval_start = end_time
current_interval_posts = []

for post in posts_list:

    post_time = datetime.utcfromtimestamp(post.created_utc)

    if post_time < current_interval_start - intervals[interval]:
        nested_posts.append(current_interval_posts)
        current_interval_posts = []
        current_interval_start = post_time

    current_interval_posts.append(fetch_post_data(post, top_comments_count))


if current_interval_posts:
    nested_posts.append(current_interval_posts)

import matplotlib.pyplot as plt

num_posts_per_interval = [len(interval_posts) for interval_posts in nested_posts]

interval_indices = list(range(len(nested_posts)))

plt.figure(figsize=(10, 6))
plt.bar(interval_indices, num_posts_per_interval, color='skyblue')
plt.xlabel('Interval Number')
plt.ylabel('Number of Posts')
plt.title(f'Number of Posts per {interval.capitalize()} Interval in r/{sub_name}')
plt.xticks(interval_indices)
plt.show()

import time
import pandas as pd
from tqdm import tqdm

def create_csv(nested_posts, top_comments_count):
    data = []
    total_posts = sum(len(posts) for posts in nested_posts)

    with tqdm(total=total_posts, desc="Processing Posts") as pbar:
        for interval_index, interval_posts in enumerate(nested_posts):
            for post in interval_posts:

                data.append({
                    'Post/Comment': 'Post',
                    'ID': post.id,
                    'Title': post.title,
                    'Text': post.selftext,
                    'Creation Date': datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d'),
                    'Interval Number': interval_index
                })

                try:

                    submission = reddit.submission(id=post.id)
                    submission.comment_sort = 'best'
                    submission.comments.replace_more(limit=None)

                    for comment in submission.comments[:top_comments_count]:
                        if hasattr(comment, "author") and comment.author:
                            data.append({
                                'Post/Comment': 'Comment',
                                'ID': comment.id,
                                'Title': '',
                                'Text': comment.body,
                                'Creation Date': datetime.utcfromtimestamp(comment.created_utc).strftime('%Y-%m-%d'),
                                'Interval Number': interval_index
                            })
                except praw.exceptions.RedditAPIException as e:
                    print(f"Rate limit exceeded. Waiting for {e.sleep_time} seconds.")
                    time.sleep(e.sleep_time)

                pbar.update(1)

    df = pd.DataFrame(data)
    df.to_csv('reddit_posts_and_comments.csv', index=True)

create_csv(nested_posts, 3)